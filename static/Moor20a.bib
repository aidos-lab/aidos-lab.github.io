@inproceedings{Moor20a,
	abstract = {We propose a novel approach for preserving topological structures of the input space in latent representations of autoencoders. Using persistent homology, a technique from topological data analysis, we calculate topological signatures of both the input and latent space to derive a topological loss term. Under weak theoretical assumptions, we construct this loss in a differentiable manner, such that the encoding learns to retain multi-scale connectivity information. We show that our approach is theoretically well-founded and that it exhibits favourable latent representations on a synthetic manifold as well as on real-world image data sets, while preserving low reconstruction errors.},
	archiveprefix = {arXiv},
	author = {Moor, Michael and Horn, Max and Rieck, Bastian and Borgwardt, Karsten},
	author+an = {1=first; 2=first; 3=highlight,last; 4=last},
	booktitle = {Proceedings of the 37th International Conference on Machine Learning~(ICML)},
	editor = {Hal Daum√©~III and Aarti Singh},
	eprint = {1906.00722},
	number = {119},
	pages = {7045--7054},
	primaryclass = {cs.LG},
	publisher = {PMLR},
	repository = {https://github.com/BorgwardtLab/topological-autoencoders},
	series = {Proceedings of Machine Learning Research},
	title = {Topological Autoencoders},
	year = {2020},
}

